{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pDU_4n3xz1tw"
   },
   "source": [
    "# Human Pose Estimation - Part 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CQU0HMRoe14h"
   },
   "source": [
    "# Human Keypoint Estimation - Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DI-J8Y-xefCe"
   },
   "source": [
    "## Download COCO Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this partial solution, look for **TODO** items. I've described what the code should do and added hints here and there, but you'll need to write it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 359910,
     "status": "ok",
     "timestamp": 1572379095525,
     "user": {
      "displayName": "Armin Kappeler",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAyyBGgsBvPtaODx-Mv5MRaJbOgdYl36kNWREWd=s64",
      "userId": "01791136915511492320"
     },
     "user_tz": -60
    },
    "id": "CNJZrbNjztws",
    "outputId": "0bc85cea-d7f0-4674-e3d4-b083cd053fd4"
   },
   "outputs": [],
   "source": [
    "# This code downloads the coco dataset from Amazon S3 in parallel.\n",
    "import boto3\n",
    "from botocore import UNSIGNED\n",
    "from botocore.client import Config\n",
    "import multiprocessing\n",
    "import subprocess\n",
    "files = ['val2017.zip', 'annotations_trainval2017.zip','train2017.zip',] \n",
    "\n",
    "s3 = boto3.client('s3', config=Config(signature_version=UNSIGNED))\n",
    "def download_and_unzip_from_s3(file_name, bucket_name='fast-ai-coco'):\n",
    "    print(\"Downloading\", file_name)\n",
    "    s3.download_file(bucket_name, file_name, file_name)\n",
    "    print(\"Finished downloading\", file_name, \". Starting to unzip.\")\n",
    "    subprocess.run([\"unzip\", file_name])\n",
    "    print(\"Finished unzipping\", file_name)\n",
    "\n",
    "# Download in parallel\n",
    "num_cpus = multiprocessing.cpu_count()\n",
    "with multiprocessing.Pool(num_cpus) as p:\n",
    "    p.map(download_and_unzip_from_s3, files)\n",
    "\n",
    "print(\"Done transferring all datasets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GeXPZ9592Afv"
   },
   "source": [
    "## Dataset Provider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CF02oor0yp0L"
   },
   "outputs": [],
   "source": [
    "# initialization\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import json\n",
    "from PIL import Image\n",
    "from scipy.io import loadmat\n",
    "from matplotlib.pyplot import imshow, show\n",
    "from matplotlib.patches import Rectangle\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from scipy.ndimage import gaussian_filter\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tcXhNsh9yp0e"
   },
   "outputs": [],
   "source": [
    "# Dataset provider\n",
    "class KeyPoseDataset(Dataset):\n",
    "    def __init__(self, path_to_annotations, base_img_path, transform=None):\n",
    "\n",
    "        # TODO: load the annotation file\n",
    "        # annotation_json = \n",
    "        \n",
    "        self.annotations = annotation_json['annotations']        \n",
    "        self.base_img_path = base_img_path\n",
    "        self.transform = transform\n",
    "        \n",
    "        # Input image is 192x256\n",
    "        self.input_width = 192\n",
    "        self.input_height = 256\n",
    "\n",
    "        # The heatmap is 4x smaller (48x64)\n",
    "        self.heatmap_width = 48\n",
    "        self.heatmap_height = 64\n",
    "        self.nr_joints = 17\n",
    "        \n",
    "        print(\"clean database\")\n",
    "        self.annotations = self.clean_db(self.annotations)\n",
    "        print(\"DONE - total nr samples: \", len(self.annotations))\n",
    "        \n",
    "    def clean_db(self,annotations):\n",
    "        annotations_new = []\n",
    "        \n",
    "        for a in annotations:\n",
    "            # remove iscrowd=True\n",
    "            if a['iscrowd'] != 0:\n",
    "                continue\n",
    "\n",
    "            # remove images with no keypoints\n",
    "            keypoints_list = np.asarray(a['keypoints'])\n",
    "            keypoints = np.reshape(keypoints_list,(17,3))\n",
    "            gt_validity = keypoints[:,2]>0\n",
    "            if sum(gt_validity) == 0:\n",
    "                continue\n",
    "\n",
    "            # remove small bounding boxes\n",
    "            x_start, y_start, box_w, box_h = a['bbox']\n",
    "            if box_w < self.heatmap_width or box_h < self.heatmap_height:\n",
    "                continue\n",
    "            \n",
    "            # add sample to dataset\n",
    "            annotations_new.append(a)\n",
    "        \n",
    "        return annotations_new\n",
    "\n",
    "    def __len__(self):\n",
    "        # TODO: return the length of annotations\n",
    "        # return \n",
    "\n",
    "    ## Generate and scale the input image\n",
    "    def get_input_image(self,annotations):\n",
    "        # Parse the annotations\n",
    "        # TODO: x_start, y_start, box_w, box_h will contain the bbox  \n",
    "        # img_id will contain the image_id\n",
    "        # x_start, y_start, box_w, box_h = \n",
    "        # img_id = str(annotations['image_id'])    \n",
    "\n",
    "        # Open to Image\n",
    "        img_name = '000000000000'\n",
    "        img_name = img_name[0:len(img_name) - len(img_id)] + img_id\n",
    "        img = Image.open(self.base_img_path + '/' + img_name + '.jpg')\n",
    "        \n",
    "        # Rescale Input Image\n",
    "        rescaled_img = img.resize((self.input_width,self.input_height), box=(x_start, y_start, x_start+box_w, y_start+box_h))\n",
    "        rescaled_img = np.array(rescaled_img)\n",
    "        \n",
    "        if len(rescaled_img.shape) != 3:\n",
    "            rescaled_img = np.stack((rescaled_img,)*3, axis=-1)\n",
    "            \n",
    "        # normalize input image\n",
    "        mean=np.asarray([0.485, 0.456, 0.406])\n",
    "        std=np.asarray([0.229, 0.224, 0.225])\n",
    "        rescaled_img = rescaled_img.astype('float32')/255.0\n",
    "        rescaled_img = (rescaled_img - mean) / std\n",
    "\n",
    "        return torch.tensor(rescaled_img).permute(2,0,1).float()\n",
    "\n",
    "    ## generate target heatmap\n",
    "    def get_groundtruth_heatmap(self,annotations,gauss_sigma=2):\n",
    "        # Parse the annotations\n",
    "        x_start, y_start, box_w, box_h = annotations['bbox']\n",
    "        keypoints_list = np.asarray(annotations['keypoints'])        \n",
    "\n",
    "        # 3 columns, x,y,v\n",
    "        keypoints = np.reshape(keypoints_list,(17,3))\n",
    "\n",
    "        box_offset = np.asarray([x_start,y_start,0])\n",
    "        box_dims = np.asarray([box_w,box_h,1])\n",
    "        heatmap_dims = np.asarray([self.heatmap_width,self.heatmap_height,1])\n",
    "\n",
    "        # rescale keypoints\n",
    "        keypoints = np.round((keypoints - box_offset) * heatmap_dims / box_dims).astype(int)\n",
    "\n",
    "        # generate gt heatmaps\n",
    "        gt_heatmap = np.zeros((self.nr_joints,self.heatmap_height,self.heatmap_width))\n",
    "        for j in range(self.nr_joints):\n",
    "            if keypoints[j,2] > 0: # only plot valid points\n",
    "                y = keypoints[j,0]\n",
    "                x = keypoints[j,1]\n",
    "\n",
    "                # skip, if x or y are out of bound\n",
    "                if x<0 or y<0 or x>=self.heatmap_height or y>=self.heatmap_width:\n",
    "                    keypoints[j,2] = 0\n",
    "                    continue \n",
    "\n",
    "                # set joint location in heatmap\n",
    "                gt_heatmap[j,x,y] = 1.0\n",
    "\n",
    "                # apply gaussian\n",
    "                gt_heatmap[j,:,:] = gaussian_filter(gt_heatmap[j,:,:], sigma=gauss_sigma, mode='constant', cval=0.0)\n",
    "\n",
    "                # normalize to 1\n",
    "                gt_heatmap[j,:,:] = gt_heatmap[j,:,:] / np.max(gt_heatmap[j,:,:]) \n",
    "\n",
    "        # get validity vector\n",
    "        gt_validity = keypoints[:,2]>0\n",
    "\n",
    "        return torch.tensor(gt_heatmap).float(), torch.tensor(gt_validity).float()\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        annotation = self.annotations[idx]\n",
    "        input_img = self.get_input_image(annotation)\n",
    "        heatmap, validity = self.get_groundtruth_heatmap(annotation)\n",
    "        \n",
    "        return {\n",
    "            'input_img': input_img, \n",
    "            'heatmap': heatmap,\n",
    "            'validity': validity\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 387023,
     "status": "ok",
     "timestamp": 1572379122656,
     "user": {
      "displayName": "Armin Kappeler",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAyyBGgsBvPtaODx-Mv5MRaJbOgdYl36kNWREWd=s64",
      "userId": "01791136915511492320"
     },
     "user_tz": -60
    },
    "id": "HQ3jF0zF975n",
    "outputId": "917f05e8-4c18-4622-b9ae-27e35e1e33e4"
   },
   "outputs": [],
   "source": [
    "# initialize Datasets\n",
    "\n",
    "train_keypose_dataset = KeyPoseDataset(path_to_annotations='./annotations/person_keypoints_train2017.json', base_img_path='./train2017')\n",
    "train_dataloader = DataLoader(train_keypose_dataset, batch_size=32,\n",
    "                        shuffle=True, num_workers=8)\n",
    "\n",
    "val_keypose_dataset = KeyPoseDataset(path_to_annotations='./annotations/person_keypoints_val2017.json', base_img_path='./val2017')\n",
    "val_dataloader = DataLoader(val_keypose_dataset, batch_size=32,\n",
    "                        shuffle=False, num_workers=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0yzcWgWD2YzA"
   },
   "source": [
    "## Model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aAnDnPxylXsd"
   },
   "outputs": [],
   "source": [
    "## Our own model architecture\n",
    "\n",
    "# Expected accuracy ~0.6\n",
    "class ConvDeconvNet(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(ConvDeconvNet,self).__init__()\n",
    "        # TODO: Convolution 1\n",
    "        # self.conv1: Conv2d layer with inchannels = 3, out_channels = 64, kernel_size = 7, stride = 2, padding = 3\n",
    "        # fill the layer weights tensor with values drawn from the normal distribution with std = 0.001\n",
    "        # fill the layer bias tensor with value 0\n",
    "        # self.bn1 is the 2d Batch Normalization layer with num_features = 64\n",
    "        # self.relu1 is the ReLU activation function\n",
    "        # define self.maxpool1 as maxpool2d with kernel_size = 2 and stride = 2\n",
    "        # self.conv1 = \n",
    "\n",
    "        \n",
    "        # TODO: Convolution 2\n",
    "        # self.conv2: Conv2d layer with inchannels = 64, out_channels = 128, kernel_size = 5, stride = 1, padding = 2\n",
    "        # fill the layer weights tensor with values drawn from the normal distribution with std = 0.001\n",
    "        # fill the layer bias tensor with value 0\n",
    "        # self.bn2 is the 2d Batch Normalization layer with num_features = 128\n",
    "        # self.relu2 is the ReLU activation function\n",
    "        # define self.maxpool2 as maxpool2d with kernel_size = 2 and stride = 2\n",
    "        # self.conv2 = \n",
    "\n",
    "        \n",
    "        # TODO: Convolution 1\n",
    "        # self.conv1: Conv2d layer with inchannels = 128, out_channels = 256, kernel_size = 5, stride = 1, padding = 2\n",
    "        # fill the layer weights tensor with values drawn from the normal distribution with std = 0.001\n",
    "        # fill the layer bias tensor with value 0\n",
    "        # self.bn3 is the 2d Batch Normalization layer with num_features = 6\n",
    "        # self.relu3 is the ReLU activation function\n",
    "        # define self.maxpool3 as maxpool2d with kernel_size = 2 and stride = 2\n",
    "        # self.conv3 = \n",
    "        \n",
    "        \n",
    "        #Deconvolution 4\n",
    "        # TODO: DeConvolution \n",
    "        # self.deconv4: ConvTranspose2d layer with inchannels = 256, out_channels = 256, padding = 1, output_padding = 0, kernel_size = 4, stride = 2\n",
    "        # EXPERIMENT WITH IT TO SEE HOW IT WORKS\n",
    "        # fill the layer weights tensor with values drawn from the normal distribution with std = 0.001\n",
    "        # self.bn4 is the 2d Batch Normalization layer with num_features = 256\n",
    "        # self.relu4 is the ReLU activation function\n",
    "        # self.deconv4 = \n",
    "        \n",
    "        \n",
    "        #Deconvolution 5\n",
    "        # TODO: DeConvolution \n",
    "        # self.deconv5: ConvTranspose2d layer with inchannels = 256, out_channels = 256, padding = 1, output_padding = 0, kernel_size = 4, stride = 2\n",
    "        # fill the layer weights tensor with values drawn from the normal distribution with std = 0.001\n",
    "        # self.bn5 is the 2d Batch Normalization layer with num_features = 256\n",
    "        # self.deconv5 =\n",
    "        \n",
    "        \n",
    "        ### final layer declaration\n",
    "        # TODO: DeConvolution \n",
    "        # self.conv6: Conv2d layer with inchannels = 256, kernel_size = 4\n",
    "        # THINK ABOUT WHAT SHOULD BE THE out_channels\n",
    "        # fill the layer weights tensor with values drawn from the normal distribution with std = 0.001\n",
    "        # fill the layer bias tensor with value 0\n",
    "        # self.conv6 =\n",
    "\n",
    "        \n",
    "    def forward(self,x):\n",
    "        # conv layer\n",
    "       # TODO: apply the conv layers on x\n",
    "        \n",
    "        # deconv layer\n",
    "        # TODO: apply the deconv layers\n",
    "        \n",
    "        # final layer\n",
    "        # TODO: apply the final layer\n",
    "        return(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eKpQ4dHin5G4"
   },
   "outputs": [],
   "source": [
    "## Resnet50 Architecture\n",
    "\n",
    "# Expected accuracy ~0.75\n",
    "\n",
    "# pytorch resnet implementation\n",
    "# https://pytorch.org/docs/stable/_modules/torchvision/models/resnet.html\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.model_zoo import load_url\n",
    "\n",
    "\n",
    "__all__ = ['ResNet', 'resnet18', 'resnet34', 'resnet50', 'resnet101',\n",
    "           'resnet152', 'resnext50_32x4d', 'resnext101_32x8d',\n",
    "           'wide_resnet50_2', 'wide_resnet101_2']\n",
    "\n",
    "\n",
    "model_urls = {\n",
    "    'resnet18': 'https://download.pytorch.org/models/resnet18-5c106cde.pth',\n",
    "    'resnet34': 'https://download.pytorch.org/models/resnet34-333f7ec4.pth',\n",
    "    'resnet50': 'https://download.pytorch.org/models/resnet50-19c8e357.pth',\n",
    "    'resnet101': 'https://download.pytorch.org/models/resnet101-5d3b4d8f.pth',\n",
    "    'resnet152': 'https://download.pytorch.org/models/resnet152-b121ed2d.pth',\n",
    "    'resnext50_32x4d': 'https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth',\n",
    "    'resnext101_32x8d': 'https://download.pytorch.org/models/resnext101_32x8d-8ba56ff5.pth',\n",
    "    'wide_resnet50_2': 'https://download.pytorch.org/models/wide_resnet50_2-95faca4d.pth',\n",
    "    'wide_resnet101_2': 'https://download.pytorch.org/models/wide_resnet101_2-32ee1156.pth',\n",
    "}\n",
    "\n",
    "def conv3x3(in_planes, out_planes, stride=1, groups=1, dilation=1):\n",
    "    \"\"\"3x3 convolution with padding\"\"\"\n",
    "    # TODO: return a 3x3 convolution. \n",
    "    \n",
    "\n",
    "\n",
    "def conv1x1(in_planes, out_planes, stride=1):\n",
    "    \"\"\"1x1 convolution\"\"\"\n",
    "    # TODO: return a 1x1 convolution. \n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\n",
    "                 base_width=64, dilation=1, norm_layer=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        if groups != 1 or base_width != 64:\n",
    "            raise ValueError('BasicBlock only supports groups=1 and base_width=64')\n",
    "        if dilation > 1:\n",
    "            raise NotImplementedError(\"Dilation > 1 not supported in BasicBlock\")\n",
    "        # Both self.conv1 and self.downsample layers downsample the input when stride != 1\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1 = norm_layer(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = norm_layer(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\n",
    "                 base_width=64, dilation=1, norm_layer=None):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        width = int(planes * (base_width / 64.)) * groups\n",
    "        # Both self.conv2 and self.downsample layers downsample the input when stride != 1\n",
    "        self.conv1 = conv1x1(inplanes, width)\n",
    "        self.bn1 = norm_layer(width)\n",
    "        self.conv2 = conv3x3(width, width, stride, groups, dilation)\n",
    "        self.bn2 = norm_layer(width)\n",
    "        self.conv3 = conv1x1(width, planes * self.expansion)\n",
    "        self.bn3 = norm_layer(planes * self.expansion)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNetPose(nn.Module):\n",
    "\n",
    "    def __init__(self, block, layers, num_classes=1000, zero_init_residual=False,\n",
    "                 groups=1, width_per_group=64, replace_stride_with_dilation=None,\n",
    "                 norm_layer=None):\n",
    "        super(ResNetPose, self).__init__()\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        self._norm_layer = norm_layer\n",
    "\n",
    "        self.inplanes = 64\n",
    "        self.dilation = 1\n",
    "        if replace_stride_with_dilation is None:\n",
    "            # each element in the tuple indicates if we should replace\n",
    "            # the 2x2 stride with a dilated convolution instead\n",
    "            replace_stride_with_dilation = [False, False, False]\n",
    "        if len(replace_stride_with_dilation) != 3:\n",
    "            raise ValueError(\"replace_stride_with_dilation should be None \"\n",
    "                             \"or a 3-element tuple, got {}\".format(replace_stride_with_dilation))\n",
    "        self.groups = groups\n",
    "        self.base_width = width_per_group\n",
    "        self.conv1 = nn.Conv2d(3, self.inplanes, kernel_size=7, stride=2, padding=3,\n",
    "                               bias=False)\n",
    "        self.bn1 = norm_layer(self.inplanes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2,\n",
    "                                       dilate=replace_stride_with_dilation[0])\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2,\n",
    "                                       dilate=replace_stride_with_dilation[1])\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2,\n",
    "                                       dilate=replace_stride_with_dilation[2])\n",
    "        \n",
    "        ### not needed\n",
    "        #self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        #self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "        # Zero-initialize the last BN in each residual branch,\n",
    "        # so that the residual branch starts with zeros, and each residual block behaves like an identity.\n",
    "        # This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677\n",
    "        if zero_init_residual:\n",
    "            for m in self.modules():\n",
    "                if isinstance(m, Bottleneck):\n",
    "                    nn.init.constant_(m.bn3.weight, 0)\n",
    "                elif isinstance(m, BasicBlock):\n",
    "                    nn.init.constant_(m.bn2.weight, 0)\n",
    "                    \n",
    "                    \n",
    "        ### deconvolutional layers declaration\n",
    "        self.deconv5 =nn.ConvTranspose2d(in_channels=2048,out_channels=256,padding=1, output_padding=0, kernel_size=4, stride=2)\n",
    "        self.bn5 = nn.BatchNorm2d(256)\n",
    "        self.relu5= nn.ReLU(inplace=True)\n",
    "        \n",
    "        self.deconv6 =nn.ConvTranspose2d(in_channels=256,out_channels=256,padding=1, output_padding=0,kernel_size=4, stride=2)\n",
    "        self.bn6 = nn.BatchNorm2d(256)\n",
    "        self.relu6= nn.ReLU(inplace=True)\n",
    "        \n",
    "        self.deconv7 =nn.ConvTranspose2d(in_channels=256,out_channels=256,padding=1, output_padding=0,kernel_size=4, stride=2)\n",
    "        self.bn7 = nn.BatchNorm2d(256)\n",
    "        self.relu7= nn.ReLU(inplace=True)\n",
    "        \n",
    "        ### final layer declaration\n",
    "        self.conv8 = nn.Conv2d(in_channels=256, out_channels=17, kernel_size=1) # 17 joints -> out_channel=17\n",
    "        \n",
    "        \n",
    "        ### init weights\n",
    "        self.init_weights()\n",
    "\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1, dilate=False):\n",
    "        norm_layer = self._norm_layer\n",
    "        downsample = None\n",
    "        previous_dilation = self.dilation\n",
    "        if dilate:\n",
    "            self.dilation *= stride\n",
    "            stride = 1\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                conv1x1(self.inplanes, planes * block.expansion, stride),\n",
    "                norm_layer(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample, self.groups,\n",
    "                            self.base_width, previous_dilation, norm_layer))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes, groups=self.groups,\n",
    "                                base_width=self.base_width, dilation=self.dilation,\n",
    "                                norm_layer=norm_layer))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "      \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        ### deconvolution layers\n",
    "        x = self.deconv5(x)\n",
    "        x = self.bn5(x)\n",
    "        x = self.relu5(x)\n",
    "        \n",
    "        x = self.deconv6(x)\n",
    "        x = self.bn6(x)\n",
    "        x = self.relu6(x)\n",
    "        \n",
    "        x = self.deconv7(x)\n",
    "        x = self.bn7(x)\n",
    "        x = self.relu7(x)\n",
    "        \n",
    "        ### final layer\n",
    "        x = self.conv8(x)\n",
    "\n",
    "        return x\n",
    "      \n",
    "    def init_weights(self):\n",
    "        \n",
    "        # init deconv layers\n",
    "        nn.init.normal_(self.deconv5.weight, std=0.001)\n",
    "        nn.init.constant_(self.deconv5.bias, 0)\n",
    "        nn.init.constant_(self.bn5.weight, 1)\n",
    "        nn.init.constant_(self.bn5.bias, 0)\n",
    "        \n",
    "        nn.init.normal_(self.deconv6.weight, std=0.001)\n",
    "        nn.init.constant_(self.deconv6.bias, 0)\n",
    "        nn.init.constant_(self.bn6.weight, 1)\n",
    "        nn.init.constant_(self.bn6.bias, 0)\n",
    "        \n",
    "        nn.init.normal_(self.deconv7.weight, std=0.001)\n",
    "        nn.init.constant_(self.deconv7.bias, 0)\n",
    "        nn.init.constant_(self.bn7.weight, 1)\n",
    "        nn.init.constant_(self.bn7.bias, 0)\n",
    "        \n",
    "        # init final layer\n",
    "        nn.init.normal_(self.conv8.weight, std=0.001)\n",
    "        nn.init.constant_(self.conv8.bias, 0)\n",
    "      \n",
    "      \n",
    "def resnetpose_pretrained():\n",
    "  \n",
    "    model = ResNetPose(Bottleneck, [3, 4, 6, 3])\n",
    "    \n",
    "    # load pretrained weights\n",
    "    state_dict = load_url(model_urls['resnet50'],progress=True)\n",
    "    model.load_state_dict(state_dict,strict=False)\n",
    "    return model\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 396132,
     "status": "ok",
     "timestamp": 1572379131778,
     "user": {
      "displayName": "Armin Kappeler",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAyyBGgsBvPtaODx-Mv5MRaJbOgdYl36kNWREWd=s64",
      "userId": "01791136915511492320"
     },
     "user_tz": -60
    },
    "id": "wESCgIEhlnpF",
    "outputId": "63ae6f00-c03c-4cfd-c9be-3a73123b047a"
   },
   "outputs": [],
   "source": [
    "## initialize model\n",
    "\n",
    "model = ConvDeconvNet() # uncomment this line for our own architecture\n",
    "# model = resnetpose_pretrained() # uncomment this line for pretrained Resnet50\n",
    "\n",
    "# check input and output dimensions\n",
    "sample = next(iter(val_dataloader))\n",
    "img = sample['input_img'][None,0]\n",
    "print(\"input dims: \", img.shape)\n",
    "print(\"output dims: \", model(img).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k1We17uUomgj"
   },
   "source": [
    "## Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s9vn3osS978t"
   },
   "outputs": [],
   "source": [
    "# Loss function\n",
    "def custom_l2_loss_closure(mse_loss_fn):\n",
    "    # We want to zero out the loss for when no label was provided in the target heatmap\n",
    "    # We can achieve this by multiply the validity tensor with the pred \n",
    "    \n",
    "    def custom_l2_loss(pred,target,validity):\n",
    "        v = validity.unsqueeze(2).unsqueeze(2)\n",
    "        pred = pred * v\n",
    "        target = target * v\n",
    "        return mse_loss_fn(pred, target)\n",
    "    \n",
    "    return custom_l2_loss\n",
    "\n",
    "loss_fn = custom_l2_loss_closure(mse_loss_fn=torch.nn.MSELoss())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GvF_fdDbeUcs"
   },
   "source": [
    "## PCK Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HXIzDo4keCW6"
   },
   "outputs": [],
   "source": [
    "# ORIGINAL FROM HERE:\n",
    "# https://github.com/microsoft/human-pose-estimation.pytorch/blob/715d29e55f59ae555116542e85ed7175d57120e6/lib/core/evaluate.py\n",
    "# ------------------------------------------------------------------------------\n",
    "# Copyright (c) Microsoft\n",
    "# Licensed under the MIT License.\n",
    "# Written by Bin Xiao (Bin.Xiao@microsoft.com)\n",
    "# ------------------------------------------------------------------------------\n",
    "# Calculates Percentage of Correct Key-points (PCK) accuracy\n",
    "# A detected joint is considered correct if the distance between the predicted \n",
    "# and the true joint is within a certain threshold. \n",
    " \n",
    "import numpy as np\n",
    "\n",
    "def get_max_preds(batch_heatmaps):\n",
    "    '''\n",
    "    get predictions from score maps\n",
    "    heatmaps: numpy.ndarray([batch_size, num_joints, height, width])\n",
    "    '''\n",
    "    assert isinstance(batch_heatmaps, np.ndarray), \\\n",
    "        'batch_heatmaps should be numpy.ndarray'\n",
    "    assert batch_heatmaps.ndim == 4, 'batch_images should be 4-ndim'\n",
    "\n",
    "    batch_size = batch_heatmaps.shape[0]\n",
    "    num_joints = batch_heatmaps.shape[1]\n",
    "    width = batch_heatmaps.shape[3]\n",
    "    heatmaps_reshaped = batch_heatmaps.reshape((batch_size, num_joints, -1))\n",
    "    idx = np.argmax(heatmaps_reshaped, 2)\n",
    "    maxvals = np.amax(heatmaps_reshaped, 2)\n",
    "\n",
    "    maxvals = maxvals.reshape((batch_size, num_joints, 1))\n",
    "    idx = idx.reshape((batch_size, num_joints, 1))\n",
    "\n",
    "    preds = np.tile(idx, (1, 1, 2)).astype(np.float32)\n",
    "\n",
    "    preds[:, :, 0] = (preds[:, :, 0]) % width\n",
    "    preds[:, :, 1] = np.floor((preds[:, :, 1]) / width)\n",
    "\n",
    "    pred_mask = np.tile(np.greater(maxvals, 0.0), (1, 1, 2))\n",
    "    pred_mask = pred_mask.astype(np.float32)\n",
    "\n",
    "    preds *= pred_mask\n",
    "    return preds, maxvals\n",
    "\n",
    "\n",
    "def calc_dists(preds, target, normalize):\n",
    "    preds = preds.astype(np.float32)\n",
    "    target = target.astype(np.float32)\n",
    "    dists = np.zeros((preds.shape[1], preds.shape[0]))\n",
    "    for n in range(preds.shape[0]):\n",
    "        for c in range(preds.shape[1]):\n",
    "            if target[n, c, 0] > 1 and target[n, c, 1] > 1:\n",
    "                normed_preds = preds[n, c, :] / normalize[n]\n",
    "                normed_targets = target[n, c, :] / normalize[n]\n",
    "                dists[c, n] = np.linalg.norm(normed_preds - normed_targets)\n",
    "            else:\n",
    "                dists[c, n] = -1\n",
    "    return dists\n",
    "\n",
    "\n",
    "def dist_acc(dists, thr=0.5):\n",
    "    ''' Return percentage below threshold while ignoring values with a -1 '''\n",
    "    dist_cal = np.not_equal(dists, -1)\n",
    "    num_dist_cal = dist_cal.sum()\n",
    "    if num_dist_cal > 0:\n",
    "        return np.less(dists[dist_cal], thr).sum() * 1.0 / num_dist_cal\n",
    "    else:\n",
    "        return -1\n",
    "\n",
    "\n",
    "def accuracy(output, target, hm_type='gaussian', thr=0.5):\n",
    "    '''\n",
    "    Calculate accuracy according to PCK,\n",
    "    but uses ground truth heatmap rather than x,y locations\n",
    "    First value to be returned is average accuracy across 'idxs',\n",
    "    followed by individual accuracies\n",
    "    '''\n",
    "    idx = list(range(output.shape[1]))\n",
    "    norm = 1.0\n",
    "    if hm_type == 'gaussian':\n",
    "        pred, _ = get_max_preds(output)\n",
    "        target, _ = get_max_preds(target)\n",
    "        h = output.shape[2]\n",
    "        w = output.shape[3]\n",
    "        norm = np.ones((pred.shape[0], 2)) * np.array([h, w]) / 10\n",
    "    dists = calc_dists(pred, target, norm)\n",
    "\n",
    "    acc = np.zeros((len(idx) + 1))\n",
    "    avg_acc = 0\n",
    "    cnt = 0\n",
    "\n",
    "    for i in range(len(idx)):\n",
    "        acc[i + 1] = dist_acc(dists[idx[i]])\n",
    "        if acc[i + 1] >= 0:\n",
    "            avg_acc = avg_acc + acc[i + 1]\n",
    "            cnt += 1\n",
    "\n",
    "    avg_acc = avg_acc / cnt if cnt != 0 else 0\n",
    "    if cnt != 0:\n",
    "        acc[0] = avg_acc\n",
    "    return avg_acc\n",
    "\n",
    "# Wrapper function to calculate accuracy for one batch\n",
    "def get_accuracy(model, dataloader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        sample_batched = next(iter(dataloader))\n",
    "        input_img = sample_batched['input_img'].to('cuda')\n",
    "        heatmap = sample_batched['heatmap'].to('cuda')\n",
    "        validity = sample_batched['validity'].to('cuda')\n",
    "        outputs = model(input_img)\n",
    "        acc_val = accuracy(outputs.cpu().numpy(),heatmap.cpu().numpy())\n",
    "            \n",
    "    model.train()\n",
    "    return acc_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3j1W2T_Bo5sv"
   },
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 953385,
     "status": "ok",
     "timestamp": 1572379689045,
     "user": {
      "displayName": "Armin Kappeler",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAyyBGgsBvPtaODx-Mv5MRaJbOgdYl36kNWREWd=s64",
      "userId": "01791136915511492320"
     },
     "user_tz": -60
    },
    "id": "RE_q2aUkfz5-",
    "outputId": "db247149-da63-4961-b06f-aac808d41c73"
   },
   "outputs": [],
   "source": [
    "# mount google drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 21104993,
     "status": "ok",
     "timestamp": 1572415412504,
     "user": {
      "displayName": "Armin Kappeler",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAyyBGgsBvPtaODx-Mv5MRaJbOgdYl36kNWREWd=s64",
      "userId": "01791136915511492320"
     },
     "user_tz": -60
    },
    "id": "DKFNgzdOyp0f",
    "outputId": "b4e87e2e-250b-43a3-c170-36273392e1be"
   },
   "outputs": [],
   "source": [
    "# Training Loop\n",
    "LEARNING_RATE = 0.0001\n",
    "NUM_EPOCHS = 10\n",
    "EXPERIMENTS_PATH=\"drive/My Drive/Manning/experiments/\"\n",
    "\n",
    "# function to store model checkpoint\n",
    "def checkpoint_model(model, optimizer, epoch, batch):\n",
    "    state = {'model': model.state_dict(), 'optimizer': optimizer.state_dict()}\n",
    "    torch.save(state, EXPERIMENTS_PATH + \"posenet_\" + str(epoch) + \"_\" + str(batch) + '.pth')\n",
    "\n",
    "# prepare model\n",
    "# TODO: Move the model to cuda and put it in train mode\n",
    "\n",
    "\n",
    "# Create the optimizer\n",
    "# TODO: Define an optimizer\n",
    "# optimizer = \n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(\n",
    "    optimizer, [8], 0.1\n",
    ")\n",
    "\n",
    "# start training loop\n",
    "for j in range(NUM_EPOCHS):\n",
    "    for i_batch, sample_batched in enumerate(train_dataloader):\n",
    "        \n",
    "        # TODO: move the input_img, heatmap, validity to cuda and save those in a variable\n",
    "        # input_img = \n",
    "        # heatmap = \n",
    "        # validity = \n",
    "        \n",
    "        # TODO: Clear out accumulated gradients\n",
    "        \n",
    "        \n",
    "        # TODO: Make a forward pass\n",
    "        # output = \n",
    "        \n",
    "        # Calculate the loss using the loss_fn\n",
    "        # loss =  \n",
    "        \n",
    "        \n",
    "        # TODO: compute gradients and update model parameters\n",
    "        \n",
    "        \n",
    "        # TODO:After each 100 batch calculate train accuracy and val accuracy and print it.\n",
    "        \n",
    "        \n",
    "        # TODO: After each 500 batch save the model. Use the function checkpoint_model with proper parameters\n",
    "        \n",
    "    \n",
    "    scheduler.step()\n",
    "checkpoint_model(model, optimizer, j, i_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dhoVlKt_fMWS"
   },
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3962,
     "status": "ok",
     "timestamp": 1572415416457,
     "user": {
      "displayName": "Armin Kappeler",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAyyBGgsBvPtaODx-Mv5MRaJbOgdYl36kNWREWd=s64",
      "userId": "01791136915511492320"
     },
     "user_tz": -60
    },
    "id": "cxg9hFxDfOaa",
    "outputId": "028b9c0c-e645-4af4-8e9c-e99d49e8d8c2"
   },
   "outputs": [],
   "source": [
    "# heatmap plotting function\n",
    "def plot_data(img_t,heatmap_t,validity_t):\n",
    "\n",
    "    # convet to numpy\n",
    "    # TODO: convert to numpy\n",
    "    # img = \n",
    "    # heatmap = \n",
    "    # validity = \n",
    "\n",
    "    # print stats\n",
    "    print(\"Image: \", img.shape, img.dtype, np.max(img), np.min(img))\n",
    "    print(\"Heatmap: \", heatmap.shape, heatmap.dtype, np.max(heatmap), np.min(heatmap))\n",
    "    print(\"Validity: \", validity.shape, validity.dtype)\n",
    "\n",
    "    # prepare data\n",
    "    img = img[0].squeeze().transpose(1,2,0)\n",
    "    mean=np.asarray([0.485, 0.456, 0.406])\n",
    "    std=np.asarray([0.229, 0.224, 0.225])\n",
    "    img = img*std + mean\n",
    "    heatmap = np.sum(heatmap[0],axis=0)\n",
    "\n",
    "    # plot data\n",
    "    fig = plt.figure(2,figsize=(20,20))\n",
    "    plt.gray()  # show the filtered result in grayscale\n",
    "    ax1 = fig.add_subplot(121)  # left side\n",
    "    ax1.imshow(img)\n",
    "    ax2 = fig.add_subplot(122)  # right side\n",
    "    ax2.imshow(heatmap)\n",
    "    plt.show()\n",
    "\n",
    "# get sample from validation set\n",
    "sample_batched = next(iter(val_dataloader))\n",
    "input_img = sample_batched['input_img'][None,0].to('cuda')\n",
    "heatmap = sample_batched['heatmap'][None,0].to('cuda')\n",
    "validity = sample_batched['validity'][None,0].to('cuda')\n",
    "\n",
    "# run inference on model\n",
    "# TODO: put the model in eval model\n",
    "# and turn off gradients before making a forward pass\n",
    "# save the forward pass result in `output` variable\n",
    "\n",
    "\n",
    "# plot groundtruth heatmap\n",
    "print (\"GROUNDTRUTH HEATMAP\")\n",
    "plot_data(input_img,heatmap,validity)\n",
    "\n",
    "# plot predicted heatmap\n",
    "print (\"PREDICTED HEATMAP\")\n",
    "plot_data(input_img,output,validity)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "HPE_Part4.ipynb",
   "provenance": [
    {
     "file_id": "1qR00MKLDgEGzdz1Ruj8R4In9_mFZtOiH",
     "timestamp": 1572116965903
    },
    {
     "file_id": "1HVN4rkbDS2IriepCoquxrYxo9J1kB6L1",
     "timestamp": 1569625920612
    }
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
